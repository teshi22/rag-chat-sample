# app.py
import os
import re
import json
from typing import Any, Dict, List

import streamlit as st
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient

# =========================
# MCP citation æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# =========================

MCP_CITATION_JSON_RE = re.compile(
    r"ã€(\d+):(\d+)â€ ([^ã€‘]+)ã€‘\s*(\{.*?\})",
    re.DOTALL,
)


def extract_mcp_chunk_map(resp) -> Dict[str, Dict[str, str]]:
    """
    citation â†’ {title, chunk} ã®è¾æ›¸ã‚’è¿”ã™
    ä¾‹:
    {
        "4:0â€ source": {
            "title": "ã€‡ã€‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            "chunk": "æœ¬æ–‡..."
        }
    }
    """
    chunk_map: Dict[str, Dict[str, str]] = {}

    for item in resp.output:
        if getattr(item, "type", None) != "mcp_call":
            continue

        output_str = getattr(item, "output", "") or ""

        for m in MCP_CITATION_JSON_RE.finditer(output_str):
            key = f"{m.group(1)}:{m.group(2)}â€ {m.group(3)}"
            json_str = m.group(4)

            try:
                data = json.loads(json_str)
            except Exception:
                continue

            chunk_map[key] = {
                "title": data.get("title", "(no title)"),
                "chunk": data.get("chunk", ""),
            }

    return chunk_map


# =========================
# Agent å‘¼ã³å‡ºã—é–¢æ•°
# =========================


def call_foundry_agent(
    user_message: str,
    history: List[Dict[str, str]],
) -> tuple[str, Dict[str, str]]:
    """
    Azure AI Foundry Agent ã‚’å©ã„ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ–‡å­—åˆ—ã¨
    MCP citation â†’ chunk ã®ãƒãƒƒãƒ—ã‚’è¿”ã™
    """

    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã‚€ï¼ˆãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    project_endpoint = os.environ.get(
        "AZURE_AI_PROJECT_ENDPOINT",
        "https://handson-aifoundry-sc.services.ai.azure.com/api/projects/handson-project",
    )
    agent_name = os.environ.get("AZURE_AI_AGENT_NAME", "knowledge-agent")

    credential = DefaultAzureCredential()

    # ä»Šå›ã¯æ¯å›ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œã‚‹ã‚·ãƒ³ãƒ—ãƒ«å®Ÿè£…
    with AIProjectClient(
        endpoint=project_endpoint, credential=credential
    ) as project_client:
        agent = project_client.agents.get(agent_name=agent_name)

        with project_client.get_openai_client() as openai_client:
            # history + ä»Šå›ã® user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ã‚’ Responses API å½¢å¼ã«å¤‰æ›
            input_messages = [
                {"role": m["role"], "content": m["content"]} for m in history
            ]
            input_messages.append({"role": "user", "content": user_message})

            response = openai_client.responses.create(
                input=input_messages,
                # ã€Œã“ã® Foundry Agent ã‚’ä½¿ãˆã€ã¨æŒ‡ç¤º
                extra_body={
                    "agent": {
                        "name": agent.name,
                        "type": "agent_reference",
                        # MCP ã®æ‰¿èªã‚’å…¨éƒ¨è‡ªå‹•ã«ã—ãŸã„å ´åˆ
                        "require_approval": "never",
                    }
                },
            )

    # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã¯ output_text ã§å–ã‚Œã‚‹
    assistant_text = getattr(response, "output_text", "") or "(no text)"

    # MCP citation â†’ chunk map
    chunk_map = extract_mcp_chunk_map(response)

    return assistant_text, chunk_map


# =========================
# Streamlit UI æœ¬ä½“
# =========================


def main():
    st.set_page_config(page_title="Foundry Agent Chat", page_icon="ğŸ’¬")

    st.title("ğŸ’¬ Azure AI Foundry Agent Chat (Streamlit)")

    st.caption(
        "Azure AI Foundry Agent + Responses API ã‚’ä½¿ã£ãŸç°¡æ˜“ãƒãƒ£ãƒƒãƒˆ UIï¼ˆMCP citation è¡¨ç¤ºä»˜ãï¼‰"
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’ä¿æŒ
    if "messages" not in st.session_state:
        st.session_state.messages: List[Dict[str, str]] = [
            {
                "role": "assistant",
                "content": "ã“ã‚“ã«ã¡ã¯ï¼Azure AI Foundry Agent ã¸ã®ãƒãƒ£ãƒƒãƒˆã§ã™ã€‚",
            }
        ]

    if "last_chunk_map" not in st.session_state:
        st.session_state.last_chunk_map: Dict[str, str] = {}

    # ã“ã‚Œã¾ã§ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # å…¥åŠ›æ¬„
    user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    if user_input:
        # ç”»é¢ã«è‡ªåˆ†ã®ç™ºè©±ã‚’å‡ºã™
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # ç›´å‰ã¾ã§ã®å±¥æ­´ã‚’æ¸¡ã—ã¦ Agent ã‚’å‘¼ã¶
        history = st.session_state.messages[:-1]  # ä»Šå›ã® user ä»¥å¤–
        with st.chat_message("assistant"):
            with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å•ã„åˆã‚ã›ä¸­..."):
                try:
                    assistant_text, chunk_map = call_foundry_agent(
                        user_message=user_input,
                        history=history,
                    )
                except Exception as e:
                    assistant_text = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                    chunk_map = {}

            st.markdown(assistant_text)

            if chunk_map:
                st.markdown("---")
                with st.expander("å‚ç…§ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
                    for key, info in chunk_map.items():
                        title = info.get("title", "(no title)")
                        chunk = info.get("chunk", "")

                        st.markdown(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {title}")

                        st.text_area(
                            label=f"chunk ({key})",
                            value=chunk,
                            height=150,
                            key=f"chunk_{key}",
                        )
                        st.markdown("---")

        # å±¥æ­´ã« assistant ã®ç™ºè©±ã‚’è¿½åŠ 
        st.session_state.messages.append(
            {"role": "assistant", "content": assistant_text}
        )
        st.session_state.last_chunk_map = chunk_map


if __name__ == "__main__":
    main()
